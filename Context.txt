Read file: Context.txt
```json
{
  "project": "Ooptions - Financial News and Market Event Analysis System",
  "description": "A comprehensive system for analyzing financial news headlines, classifying market events, matching them to historical patterns, generating trading recommendations based on macro data and event analysis, and evaluating trade performance.",
  "version": "1.4.5",
  "api_dependencies": {
    "openai": {
      "description": "Used for headline classification and trade recommendation generation",
      "configuration": {
        "api_key_source": ["OPENAI_API_KEY environment variable", "system environment"],
        "default_model": "gpt-3.5-turbo",
        "error_handling": "Robust retry mechanism with exponential backoff",
        "fallback": "DummyClassifier when API is unavailable"
      }
    },
    "fred": {
      "description": "Federal Reserve Economic Data - used for macroeconomic indicators",
      "configuration": {
        "api_key_source": "FRED_API_KEY environment variable",
        "cache_mechanism": "macro_data_cache.json with configurable expiry"
      }
    },
    "yfinance": {
      "description": "Yahoo Finance API for market data and options chains",
      "configuration": {
        "api_key_required": false,
        "cache_mechanism": "In-memory cache with timeout"
      }
    }
  },
  "core_components": {
    "data_collection": {
      "rss_ingestor": {
        "purpose": "Fetches financial headlines from various RSS feeds",
        "feeds": ["Yahoo Finance", "CNBC", "Reuters", "Financial Times", "Bloomberg"],
        "output": "List of headline dictionaries with title, source, published date",
        "code_content": "Contains functions for parsing RSS feeds and extracting headline data."
      },
      "macro_data_collector": {
        "purpose": "Collects and caches macroeconomic indicators",
        "data_sources": ["FRED API", "Yahoo Finance", "CSV fallback"],
        "indicators": ["CPI", "Fed Funds Rate", "Unemployment", "Treasury Yields"],
        "output": "Dictionary of macro indicators with values and timestamps",
        "code_content": "Includes API integration for data retrieval and caching mechanisms."
      },
      "options_data_collector": {
        "purpose": "Fetches options market metrics",
        "metrics": ["IV", "Put/Call Ratio", "Open Interest", "ATM/OTM values"],
        "output": "Options snapshot dictionary for a given ticker",
        "code_content": "Implements data fetching and processing for options metrics."
      },
      "technical_indicator_collector": {
        "purpose": "Calculates technical indicators for stocks",
        "indicators": ["RSI", "MACD", "Moving Averages"],
        "output": "Technical indicator dictionary for a given ticker",
        "code_content": "Contains algorithms for calculating various technical indicators."
      }
    },
    "analysis": {
      "llm_event_classifier": {
        "purpose": "Classifies financial headlines by type, sentiment, sector",
        "implementation": ["OpenAIClassifier", "DummyClassifier (fallback)"],
        "output": "Classification dictionary with event_type, sentiment, sector, trade recommendation",
        "code_content": "Utilizes machine learning models for classification tasks."
      },
      "event_tagger": {
        "purpose": "Adds contextual tags to financial events",
        "tags": ["surprise_positive", "is_fed_week", "is_cpi_week", "is_earnings_season", "is_repeat_event"],
        "output": "Dictionary of boolean event tags",
        "code_content": "Applies rules and logic for tagging events with context."
      },
      "prompt_context_builder": {
        "purpose": "Enriches prompts with economic context",
        "enhancements": ["time_aware_context", "delta_description", "relevance_weights"],
        "output": "Enhanced prompt context dictionary",
        "code_content": "Generates enriched prompts using contextual data."
      },
      "historical_matcher": {
        "purpose": "Matches events to historical patterns",
        "matching_mechanism": "Semantic similarity with templates",
        "output": "List of similar historical events with match scores",
        "code_content": "Implements pattern matching algorithms for historical data."
      },
      "sentiment_analyzer": {
        "purpose": "Analyzes sentiment in financial texts",
        "output": "Sentiment metrics and historical comparisons",
        "code_content": "Performs sentiment analysis using text processing techniques."
      }
    },
    "recommendation": {
      "trade_picker": {
        "purpose": "Generates trade ideas based on event analysis",
        "output": "Trade recommendation with ticker, option_type, strike, expiry, rationale",
        "code_content": "Generates trade recommendations using analysis results."
      },
      "llm_event_query": {
        "purpose": "Main entry point for user queries",
        "features": ["Natural language parsing", "Historical event matching", "Trade generation"],
        "output": "Complete analysis with market impact and trade recommendation",
        "code_content": "Handles user queries and integrates various analysis components. Key functionalities include natural language processing, data integration, trade idea generation, error handling, crypto and ticker standardization, historical data analysis, interactive and continuous modes, and session management."
      }
    },
    "persistence": {
      "trade_persistence": {
        "purpose": "Stores trade recommendations",
        "storage": "trade_history.json file",
        "schema": "JSON with headline, similar_events, trade_idea, metadata",
        "code_content": "Manages storage and retrieval of trade data."
      },
      "analysis_persistence": {
        "purpose": "Stores historical analyses",
        "storage": "analysis_history/ directory structure",
        "components": ["events/", "similar_events/", "queries/", "analysis_index.json"],
        "cloud_integration": "Optional via CLOUD_STORAGE_API_KEY",
        "code_content": "Handles storage of analysis data and supports cloud integration. Recently optimized with timestamp methods and directory caching.",
        "optimizations": {
          "timestamp_handling": "Reusable methods for timestamp generation",
          "path_caching": "Directory path caching with LRU cache for performance",
          "functions": ["_get_formatted_timestamp()", "_get_filename_timestamp()", "_get_subdir_path()"]
        }
      },
      "evaluation": {
        "purpose": "Evaluates trade performance",
        "storage": "evaluated_trades.json",
        "metrics": ["actual_return", "max_profit", "success_rate"],
        "code_content": "Evaluates trade outcomes and records performance metrics."
      }
    }
  },
  "interfaces": {
    "cli": {
      "main": "python llm_event_query.py \"query text\"",
      "view_trades": "python view_trades.py [view|stats]",
      "view_analysis": "python view_analysis.py [list|show|history|stats|export|delete|reindex|cleanup]",
      "files": {
        "view_trades": "view_trades.py (7.6KB, 233 lines)",
        "view_analysis": "view_analysis.py (31KB, 997 lines)"
      },
      "view_analysis_features": {
        "description": "Command-line tool for viewing and managing analysis results",
        "commands": {
          "list": "List saved analyses with filtering options",
          "show": "Display detailed information about a specific analysis",
          "history": "View query history with search capabilities and export option",
          "stats": "Show statistics about saved analyses",
          "export": "Export analyses to a file with batch processing",
          "delete": "Delete a specific analysis with smart metadata handling and skip confirmation option",
          "reindex": "Rebuild the analysis index from scratch",
          "cleanup": "Clean up temporary files that might be left over from incomplete operations"
        },
        "optimizations": {
          "caching": "LRU caching for file operations (@lru_cache) to reduce disk I/O operations",
          "batch_processing": "Process files in smaller batches to optimize memory usage",
          "modular_design": "Helper functions for better code organization and reuse",
          "progress_reporting": "User feedback during lengthy operations",
          "statistics_caching": "Cache for statistics to avoid recalculating them frequently",
          "path_optimization": "Utility to convert absolute paths to relative paths for memory efficiency",
          "script_friendly": "Options to skip confirmations for automated usage in scripts"
        }
      }
    },
    "web": {
      "streamlit": "streamlit run streamlit_app.py",
      "files": {
        "main_app": "streamlit_app.py (98KB, 2978 lines)",
        "readme": "README_STREAMLIT.md (3.5KB, 86 lines)"
      }
    }
  },
  "data_flow": [
    "1. rss_ingestor.py → llm_event_classifier.py → trade_picker.py → trade_persistence.py",
    "2. llm_event_query.py → [macro_data + options_data + event_tags] → OpenAI API → trade recommendation",
    "3. llm_event_query.py → historical_matcher.py → analysis_persistence.py",
    "4. evaluation_runner.py → evaluator.py → evaluated_trades.json"
  ],
  "authentication": {
    "openai_api": {
      "status": "Needs valid API key in .env file or Streamlit secrets",
      "environment_variable": "OPENAI_API_KEY",
      "fallback_variables": ["OPENAI_KEY", "TOMI_OPENAI_KEY"],
      "fallback": "DummyClassifier provides rule-based classification"
    },
    "fred_api": {
      "status": "Working",
      "environment_variable": "FRED_API_KEY",
      "fallback_variables": ["TOMI_FRED_API_KEY"],
      "configuration": "FRED_API_KEY in environment variables or Streamlit secrets"
    }
  },
  "performance_optimizations": {
    "file_operations": {
      "description": "Optimized file I/O operations with caching",
      "implementation": {
        "analysis_persistence.py": "Directory path caching and timestamp optimization",
        "view_analysis.py": "File content caching with @lru_cache for reduced disk reads",
        "key_functions": ["_load_analysis_with_cache()", "_get_full_path()", "_get_cached_statistics()"]
      },
      "benefits": [
        "Significant reduction in redundant disk I/O operations",
        "Improved response time for file-heavy operations",
        "Better user experience with faster data retrieval"
      ]
    },
    "memory_management": {
      "description": "Optimized memory usage for large datasets",
      "implementation": {
        "view_analysis.py": "Batch processing for heavy operations",
        "key_improvements": [
          "Process files in configurable batch sizes",
          "Display_analyses_batch in list_analyses",
          "Process_analyses_batch in export_analyses",
          "Modular section formatting in show_analysis",
          "Path optimization with relative paths",
          "Limited display for large data lists"
        ]
      },
      "benefits": [
        "Reduced memory footprint when processing large datasets",
        "Better performance with limited system resources",
        "Progressive processing with user feedback",
        "More responsive application even with large analysis files"
      ]
    },
    "code_structure": {
      "description": "Improved code organization and maintainability",
      "implementation": {
        "view_analysis.py": "Consolidated redundant code with helper functions",
        "key_improvements": [
          "Helper functions like clean_matching_files to eliminate code duplication",
          "Nested function definitions for better scoping",
          "Shared utility functions for path handling",
          "Improved error handling with specific error messages"
        ]
      },
      "benefits": [
        "Easier maintenance and future enhancements",
        "Better readability and code organization",
        "Simplified debugging and testing",
        "Reduced cognitive load when working with the codebase"
      ]
    },
    "automation_support": {
      "description": "Added features for automation and scripting",
      "implementation": {
        "view_analysis.py": "Skip confirmation options and export capabilities",
        "key_improvements": [
          "Added --force flag to delete command for skipping confirmation",
          "Implemented export option for query history",
          "Return values to indicate success/failure for script integration",
          "Cleanup utility for maintenance automation"
        ]
      },
      "benefits": [
        "Better support for automated workflows",
        "Integration with CI/CD pipelines",
        "Script-friendly interface for maintenance tasks",
        "More consistent state management"
      ]
    }
  },
  "current_issues": [
    "Need valid OpenAI API key in environment variables",
    "Ensure consistent data flow between components",
    "Improve error handling for external API dependencies"
  ],
  "future_enhancements": [
    "Implement machine learning for reinforcement learning from trade outcomes",
    "Add more robust error handling for external API dependencies",
    "Expand cryptocurrency support and specialized analysis",
    "Develop comprehensive backtesting framework",
    "Add real-time alerting for high-confidence trade signals",
    "Add proper logging system instead of print statements",
    "Implement configuration management for constants and settings",
    "Add file locking for multi-user access",
    "Improve path security to prevent traversal attacks",
    "Add performance monitoring and metrics"
  ],
  "styling_guidelines": [
    "IMPORTANT: Maintain the modern terminal-inspired dark theme throughout all features",
    "DO NOT remove or significantly alter existing UI elements or features without explicit instructions",
    "Keep consistent font colors (#ffffff for standard text, #00ff00 for accents and highlights)",
    "Use darker gray (#121212) for main background and lighter gray (#1a1a1a) for panels and containers",
    "Maintain rounded corners (4px radius) on all UI elements for a cleaner, modern look",
    "Always use 'Courier New', monospace font family for all text elements",
    "Maintain the tabbed interface with COMMAND and NEWS FEED tabs",
    "Preserve real-time updates and refresh indicators in the news feed",
    "Keep the status bar at the bottom with session information and timestamp",
    "Ensure draggable widgets maintain consistent styling with the terminal theme",
    "Use uppercase text for headers, buttons, and important UI elements",
    "Avoid text decoration (underlines) in headlines and navigation elements",
    "Use only green colors for all accent elements - NO orange, pink, or blue accents anywhere",
    "Use #cccccc for muted text instead of darker grays to ensure readability",
    "Maintain current functionality while enhancing visual consistency"
  ],
  "development_rules": [
    "NEVER ADD OR REMOVE FEATURES WITHOUT EXPLICIT INSTRUCTIONS",
    "ONLY IMPLEMENT WHAT IS SPECIFICALLY REQUESTED",
    "DO NOT MODIFY EXISTING FUNCTIONALITY UNLESS DIRECTLY INSTRUCTED TO DO SO",
    "PRESERVE ALL EXISTING UI COMPONENTS INCLUDING THE NEWS TERMINAL",
    "MAINTAIN EXACT FUNCTIONALITY OF ALL COMPONENTS UNLESS SPECIFICALLY ASKED TO CHANGE THEM",
    "DO NOT MAKE ASSUMPTIONS ABOUT DESIRED CHANGES - STRICTLY FOLLOW EXACT REQUIREMENTS",
    "WHEN IN DOUBT, MAINTAIN CURRENT FUNCTIONALITY RATHER THAN INTRODUCING NEW FEATURES",
    "FOCUS EXCLUSIVELY ON IMPLEMENTING THE SPECIFIC REQUESTED CHANGES WITHOUT SCOPE CREEP",
    "PRESERVE ALL TERMINAL STYLING WITH THE NEW COLOR SCHEME AND DESIGN ELEMENTS",
    "THE NEWS TERMINAL AND EXISTING TABS MUST ALWAYS REMAIN FUNCTIONAL AND UNCHANGED UNLESS EXPLICITLY REQUESTED",
    "STRICTLY ADHERE TO THE UPDATED COLOR SCHEME: DARK GRAY BACKGROUND, GREEN ACCENTS, WHITE TEXT, ROUNDED CORNERS",
    "NEVER USE DUMMY VARIABLES OR FALLBACKS INSTEAD OF ACTUAL API SERVICES",
    "ALWAYS USE THE PROVIDED API KEYS - NEVER SUBSTITUTE WITH PLACEHOLDERS OR DUMMY IMPLEMENTATIONS"
  ]
}```

